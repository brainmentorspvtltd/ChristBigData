{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "037a1a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c33efb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5c88af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"ExampleP2\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb04d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.textFile(\"pyspark_intro.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05a4a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2188e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_2 = rdd.flatMap(lambda x : x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "732a4503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Batch', 'Processing', '-', 'Hadoop', '', 'Real', 'time', 'Processing', '-', 'Spark', '', 'Spark', '-', 'Real-time', 'Processing', 'framework', '-', 'Open', 'Source', 'cluster', 'computing', 'framework', '-', 'founded', 'by', 'Apache', 'Foundation', '-', 'programming', 'used', 'by', 'Spark', 'is', 'known', 'as', 'Scala', 'and', 'Java', '-', 'Fault', 'tolerant', '-', 'High', 'Speed', 'framework', '-', 'Cache', '&', 'Persistence', '', '', 'PySpark', 'modules', '-', 'RDD', '-', 'Resilient', 'Distributed', 'Dataset', '(abstraction', 'layer', 'in', 'spark)', '-', 'DataFrame', 'and', 'SQL', '-', 'Pyspark', 'Streaming', '-', 'PySpark', 'MLib', '-', 'PySpark', 'GraphFrames', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "print(rdd_2.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17d18b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_3 = rdd_2.map(lambda x : (x,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c28a0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Batch', 1), ('Processing', 1), ('-', 1), ('Hadoop', 1), ('', 1), ('Real', 1), ('time', 1), ('Processing', 1), ('-', 1), ('Spark', 1), ('', 1), ('Spark', 1), ('-', 1), ('Real-time', 1), ('Processing', 1), ('framework', 1), ('-', 1), ('Open', 1), ('Source', 1), ('cluster', 1), ('computing', 1), ('framework', 1), ('-', 1), ('founded', 1), ('by', 1), ('Apache', 1), ('Foundation', 1), ('-', 1), ('programming', 1), ('used', 1), ('by', 1), ('Spark', 1), ('is', 1), ('known', 1), ('as', 1), ('Scala', 1), ('and', 1), ('Java', 1), ('-', 1), ('Fault', 1), ('tolerant', 1), ('-', 1), ('High', 1), ('Speed', 1), ('framework', 1), ('-', 1), ('Cache', 1), ('&', 1), ('Persistence', 1), ('', 1), ('', 1), ('PySpark', 1), ('modules', 1), ('-', 1), ('RDD', 1), ('-', 1), ('Resilient', 1), ('Distributed', 1), ('Dataset', 1), ('(abstraction', 1), ('layer', 1), ('in', 1), ('spark)', 1), ('-', 1), ('DataFrame', 1), ('and', 1), ('SQL', 1), ('-', 1), ('Pyspark', 1), ('Streaming', 1), ('-', 1), ('PySpark', 1), ('MLib', 1), ('-', 1), ('PySpark', 1), ('GraphFrames', 1), ('', 1), ('', 1), ('', 1), ('', 1), ('', 1), ('', 1), ('', 1), ('', 1), ('', 1), ('', 1), ('', 1), ('', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(rdd_3.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f2df15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_4 = rdd_3.reduceByKey(lambda a,b : a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f7869b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Batch', 1), ('Processing', 3), ('-', 15), ('Hadoop', 1), ('', 16), ('Real', 1), ('time', 1), ('Spark', 3), ('Real-time', 1), ('framework', 3), ('Open', 1), ('Source', 1), ('cluster', 1), ('computing', 1), ('founded', 1), ('by', 2), ('Apache', 1), ('Foundation', 1), ('programming', 1), ('used', 1), ('is', 1), ('known', 1), ('as', 1), ('Scala', 1), ('and', 2), ('Java', 1), ('Fault', 1), ('tolerant', 1), ('High', 1), ('Speed', 1), ('Cache', 1), ('&', 1), ('Persistence', 1), ('PySpark', 3), ('modules', 1), ('RDD', 1), ('Resilient', 1), ('Distributed', 1), ('Dataset', 1), ('(abstraction', 1), ('layer', 1), ('in', 1), ('spark)', 1), ('DataFrame', 1), ('SQL', 1), ('Pyspark', 1), ('Streaming', 1), ('MLib', 1), ('GraphFrames', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(rdd_4.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c491213b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
